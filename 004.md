#  ZFS
__Домашнее задание__

Практические навыки работы с ZFS.

__Цель__:

Отрабатываем навыки работы с созданием томов export/import и установкой параметров.
* Определить алгоритм с наилучшим сжатием - [определен](#1): gzip9
* Определить настройки pool’a - [определены](#2)
* Найти сообщение от преподавателей - [найдено](#3)

__Результат__: 
* список команд которыми получен результат с их выводами 
  
__1. Определить алгоритм с наилучшим сжатием__

Зачем: 
Отрабатываем навыки работы с созданием томов и установкой параметров. Находим наилучшее сжатие.

__Шаги__:
* определить какие алгоритмы сжатия поддерживает zfs (gzip gzip-N, zle lzjb, lz4)
* создать 4 файловых системы на каждой применить свой алгоритм сжатия.
  Для сжатия использовать либо текстовый файл, либо группу файлов:
  * либо скачать файл “Война и мир” и расположить на файловой системе 
  ```shell
    wget -O War_and_Peace.txt http://www.gutenberg.org/ebooks/2600.txt.utf-8 
  ```
  * либо скачать файл ядра распаковать и расположить на файловой системе

__Результат__:
* список команд которыми получен результат с их выводами
* вывод команды из которой видно какой из алгоритмов лучше 
  
__2. Определить настройки pool’a__

__Зачем__: 
Для переноса дисков между системами используется функция export/import. Отрабатываем навыки работы с файловой системой ZFS

__Шаги__:
* Загрузить архив с файлами локально. https://drive.google.com/open?id=1KRBNW33QWqbvbVHa3hLJivOAt60yukkg
* Распаковать.
* С помощью команды zfs import собрать pool ZFS.
* Командами zfs определить настройки
  * размер хранилища
  * тип pool
  * значение recordsize
  * какое сжатие используется
  * какая контрольная сумма используется - алгоритм

Результат:
  * список команд которыми восстановили pool. Желательно с Output команд.
  * файл с описанием настроек settings

__3. Найти сообщение от преподавателей__

__Зачем__: 
* для бэкапа используются технологии snapshot. Snapshot можно передавать между хостами и восстанавливать с помощью send/receive. Отрабатываем навыки восстановления snapshot и переноса файла.

__Шаги__:
* Скопировать файл из удаленной директории. https://drive.google.com/file/d/1gH8gCL9y7Nd5Ti3IRmplZPF1XjzxeRAG/view?usp=sharing Файл был получен командой zfs send otus/storage@task2 > otus_task2.file
* Восстановить файл локально. zfs receive
* Найти зашифрованное сообщение в файле secret_message

__Результат__:
* список шагов которыми восстанавливали
* зашифрованное сообщение

## Результат

__Внимание__: здесь и далее команды запускаются внутри VM, то есть в терминале значится метка `[vagrant@lvm ~]$`, если не сказано иное.

* Определить алгоритм с наилучшим сжатием - [определен](#1): gzip9
* Определить настройки pool’a - [определены](#2)
* Найти сообщение от преподавателей - [найдено](#3)

## Исполнение

[Vagrantfile](./004/src/Vagrantfile) образа.
```shell
  vagrant ssh server
```

### 1. Определить алгоритм с наилучшим сжатием

Текущее распределение дискового пространства:

```shell
lsblk
    NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
    sda      8:0    0  10G  0 disk 
    `-sda1   8:1    0  10G  0 part /
    sdb      8:16   0   1G  0 disk 
    sdc      8:32   0   1G  0 disk 
    sdd      8:48   0   1G  0 disk 
    sde      8:64   0   1G  0 disk 
    sdf      8:80   0   1G  0 disk 
    sdg      8:96   0   1G  0 disk 

```

Значение "сжатия":
* off 
* on 
* lzjb 
* gzip 
* gzip-[1-9] 
* zle 
* lz4

Создадим под каждый вид сжатия свой раздел:

```shell
sudo zpool create raw_drive sdb
sudo zpool create lzjb_drive sdc
sudo zpool create gzip1_drive sdd
sudo zpool create gzip9_drive sde
sudo zpool create zle_drive sdf
sudo zpool create lz4_drive sdg

zpool list
    NAME          SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
    gzip1_drive   960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
    gzip9_drive   960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
    lz4_drive     960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
    lzjb_drive    960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
    raw_drive     960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
    zle_drive     960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -


sudo zfs set compression=off raw_drive
sudo zfs set compression=lzjb lzjb_drive
sudo zfs set compression=gzip-1 gzip1_drive
sudo zfs set compression=gzip-9 gzip9_drive
sudo zfs set compression=zle lzjb_drive
sudo zfs set compression=lz4 lz4_drive

zpool list
    NAME          SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
    gzip1_drive   960M   146K   960M        -         -     0%     0%  1.00x    ONLINE  -
    gzip9_drive   960M   141K   960M        -         -     0%     0%  1.00x    ONLINE  -
    lz4_drive     960M   141K   960M        -         -     0%     0%  1.00x    ONLINE  -
    lzjb_drive    960M   158K   960M        -         -     0%     0%  1.00x    ONLINE  -
    raw_drive     960M   120K   960M        -         -     0%     0%  1.00x    ONLINE  -
    zle_drive     960M  94.5K   960M        -         -     0%     0%  1.00x    ONLINE  -
                          ^
                  !!!изменилось!!!
```
__Замечание__: занимаемое в разделах пространсов немного повысилось - при этом диски еще фактически не содеержат данных. Видимо в самих разделах хранится информация о применяемом на нем сжатии.

```shell
pwd
    /home/vagrant

curl -J -L https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.12.9.tar.xz --output linux-3.12.9.tar.xz
tar -xf linux-3.12.9.tar.xz

sudo cp -r ./linux-3.12.9 /raw_drive
sudo cp -r ./linux-3.12.9 /gzip1_drive
sudo cp -r ./linux-3.12.9 /gzip9_drive
sudo cp -r ./linux-3.12.9 /lz4_drive
sudo cp -r ./linux-3.12.9 /lzjb_drive
sudo cp -r ./linux-3.12.9 /zle_drive

```

<a name="1"></a>

```shell
du -s /raw_drive   | awk '{print $1}' 557921 - образец
du -s /gzip1_drive | awk '{print $1}' 193264 - сжало в 2.89 раза
du -s /gzip9_drive | awk '{print $1}' 171251 - сжало в 3.26 раза
du -s /lz4_drive   | awk '{print $1}' 250890 - сжало в 2.22 раза
du -s /lzjb_drive  | awk '{print $1}' 535367 - сжало в 1.04 раза
du -s /zle_drive   | awk '{print $1}' 557920 - сжало в 1.000002 раза

zpool list
```

__Вопрос__: почему разнИтся с этим? хотя все же порядок следования типов сжатия сохранен.

```shell
zfs get compressratio
  NAME         PROPERTY       VALUE  SOURCE
  gzip1_drive  compressratio  3.18x  -
  gzip9_drive  compressratio  3.64x  -
  lz4_drive    compressratio  2.40x  -
  lzjb_drive   compressratio  1.08x  -
  raw_drive    compressratio  1.00x  -
  zle_drive    compressratio  1.00x  -
```

### 2. Определить настройки pool’a 

__Замечание__: не смог продолжить на той же машинке, пришлось пересобрать "чистую".

__Замечание__: для документа https://drive.google.com/open?id=1KRBNW33QWqbvbVHa3hLJivOAt60yukkg корректная ссылка для скачивания https://docs.google.com/uc?export=download&id=1KRBNW33QWqbvbVHa3hLJivOAt60yukkg 
```shell
curl -L -J 'https://docs.google.com/uc?export=download&id=1KRBNW33QWqbvbVHa3hLJivOAt60yukkg' --output zfs_task1.tar
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
    100   388    0   388    0     0     81      0 --:--:--  0:00:04 --:--:--    81
    100 7104k    0 7104k    0     0   561k      0 --:--:--  0:00:12 --:--:-- 1001k
tar -xf zfs_task1.tar
ls
    zfs_task1.tar  zpoolexport

ls -la zpoolexport
    total 1024000
    drwxr-xr-x. 2 vagrant vagrant        32 May 15  2020 .
    drwx------. 4 vagrant vagrant       114 May 16 21:55 ..
    -rw-r--r--. 1 vagrant vagrant 524288000 May 15  2020 filea
    -rw-r--r--. 1 vagrant vagrant 524288000 May 15  2020 fileb

sudo zpool import -a -f -d fileb

sudo zpool list
    NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
    otus   480M  2.12M   478M        -         -     0%     0%  1.00x  DEGRADED  -
            ^
            ВОТ

  
zpool status
      pool: otus
     state: DEGRADED
    status: One or more devices could not be opened.  Sufficient replicas exist for
            the pool to continue functioning in a degraded state.
    action: Attach the missing device and online it using 'zpool online'.
       see: http://zfsonlinux.org/msg/ZFS-8000-2Q
      scan: none requested
    config:
        NAME                                 STATE     READ WRITE CKSUM
        otus                                 DEGRADED     0     0     0
          mirror-0                           DEGRADED     0     0     0  <--- ВОТ
            6859274022954884342              UNAVAIL      0     0     0  was /root/zpoolexport/filea
            /home/vagrant/zpoolexport/fileb  ONLINE       0     0     0

errors: No known data errors
sudo zfs get all 
    ...
    otus            recordsize            128K  
    otus            checksum              sha256                 local
zfs get compression /otus
    NAME  PROPERTY     VALUE     SOURCE
    otus  compression  zle       local    <span style="color:red"><--- в результат</span>.

<a name="2"></a>
Установлены:
  * размер хранилища = 480M
  * тип pool = mirror-0 
  * значение recordsize = 128K (sudo zfs get all)
  * какое сжатие используется = zle
  * какая контрольная сумма используется = sha256
  * файл с описанием настроек settings - это что?
```
