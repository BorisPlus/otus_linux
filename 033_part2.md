#  Сетевые пакеты. LACP 

Начну c того, что для реализации рабочего стенда было перелопачено достаточно много материала. Менялись дистрибутивы, менялись ядра, менялись версии операционок, менялись утилиты настройки (Итог - CentOS 7 и БЕЗ NetworkManager). С целью экономии времени разработки и отладки я развернул отдельный стенд для этой задачи, просто 2 узла и 2 канала между ними. Если действительно необходимо для сдачи ДЗ, то я объединю блок с общим репозиторием сети "предприятия". Но "математика" одна (названия узлов сохранены).

* https://centos.name/?page/tipsandtricks/BondingInterfaces
* https://ahelpme.com/linux/centos-8/adding-bonding-interface-to-centos-8-editing-configuration-files-only/
* https://github.com/simonmcc/vagrant-bond/blob/master/shell/convert2bond.sh
* https://help.ubuntu.com/community/UbuntuBonding

## Исполнение

Очень важно понимать, что должно быть именно ДВА независимых ФИЗИЧЕСКИХ канала, будто это два провайдера. Соответсвенно в [Vagrantfile](./033_part2/vm/Vagrantfile) это каналы адапторов: 

<details><summary>см. Vagrantfile</summary>

```text
# -*- mode: ruby -*-
# vim: set ft=ruby :

MACHINES = {
    :inetRouter => {
        :box_name => "centos/7",
        :net => [
            {adapter: 2, virtualbox__intnet: "channel_1",},
            {adapter: 3, virtualbox__intnet: "channel_1",}
        ]
    },
    :centralRouter => {
        :box_name => "centos/7",
        :net => [
            {adapter: 2, virtualbox__intnet: "channel_1",},
            {adapter: 3, virtualbox__intnet: "channel_1",},
        ]
    },
}

Vagrant.configure("2") do |config|

    MACHINES.each do |boxname, boxconfig|
        config.gatling.rsync_on_startup = false
        config.vm.define boxname do |box|
            box.vm.provision "shell", run: "always", inline: <<-SHELL

                systemctl stop NetworkManager    # <--- No once anymore
                systemctl disable NetworkManager # <--- No once anymore

                systemctl enable network.service
                systemctl start network.service

            SHELL

            config.vm.provider "virtualbox" do |v|
                v.memory = 256
                v.cpus = 1
            end

            box.vm.box = boxconfig[:box_name]
            box.vm.host_name = boxname.to_s

            boxconfig[:net].each do |ipconf|
                box.vm.network "private_network", ipconf
            end

            box.vm.provision "shell", inline: <<-SHELL
                mkdir -p ~root/.ssh
                cp ~vagrant/.ssh/auth* ~root/.ssh
            SHELL

        end
    end
end

```

</details>

```shell
cd ../vm/
vagrant destroy -f && vagrant up 
python3 v2a.py -o ../ansible/inventories/hosts # Это уже как кредо
cd ../ansible/
ansible-playbook playbooks/create_bond.yml 
ansible-playbook playbooks/demonstrate.yml 

```

[лог `ansible-playbook playbooks/create_bond.yml`](./033_part2/files/playbooks_create_bond.yml.log)

<details><summary>см. лог `ansible-playbook playbooks/create_bond.yml`</summary>

```text

PLAY [Playbook of bond config] *************************************************

TASK [Gathering Facts] *********************************************************
ok: [inetRouter]
ok: [centralRouter]

TASK [../roles/create_bond : /etc/sysconfig/network | "NOZEROCONF=yes" | I don't want 169.254.0.0/16 network at default] ***
changed: [centralRouter]
changed: [inetRouter]

TASK [../roles/create_bond : rm -f modprobe.conf] ******************************
changed: [inetRouter]
changed: [centralRouter]

TASK [../roles/create_bond : Configure modprobe.conf] **************************
changed: [inetRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.1', 'NETMASK': '255.255.255.0', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
skipping: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True}) 
skipping: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True}) 
changed: [centralRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.2', 'NETMASK': '255.255.255.0', 'GATEWAY': '10.1.1.1', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
skipping: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True}) 
skipping: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True}) 

TASK [../roles/create_bond : /etc/sysconfig/network-scripts/ifcfg-<bonded> | delete bond] ***
changed: [inetRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.1', 'NETMASK': '255.255.255.0', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
changed: [centralRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.2', 'NETMASK': '255.255.255.0', 'GATEWAY': '10.1.1.1', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
changed: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})

TASK [../roles/create_bond : /etc/sysconfig/network-scripts/ifcfg-<bonded> | create bond] ***
changed: [centralRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.2', 'NETMASK': '255.255.255.0', 'GATEWAY': '10.1.1.1', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
changed: [inetRouter] => (item={'DEVICE': 'bond0', 'TYPE': 'Bond', 'IPADDR': '10.1.1.1', 'NETMASK': '255.255.255.0', 'ONBOOT': True, 'USERCTL': False, 'BOOTPROTO': 'none', 'BONDING_OPTS': '"miimon=100 mode=0"'})
changed: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth1', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [inetRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})
changed: [centralRouter] => (item={'TYPE': 'Ethernet', 'DEVICE': 'eth2', 'BOOTPROTO': 'none', 'ONBOOT': True, 'USERCTL': False, 'MASTER': 'bond0', 'SLAVE': True})

RUNNING HANDLER [../roles/create_bond : systemctl-restart-network] *************
changed: [inetRouter]
changed: [centralRouter]

PLAY RECAP *********************************************************************
centralRouter              : ok=7    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
inetRouter                 : ok=7    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


```

</details>

## Демонстрация работоспособности

__Замечание__: ключевой момент - это именно работа с `/etc/modprobe.conf`, лишь в одной статье говорится об этом, так как обычно опуци работы с `bond` включаются тут де в файл  `/etc/sysconfig/network-scripts/ifcfg-bond`. 

Для `inetRouter`:


<details><summary>см. содержание `/proc/net/bonding/bond0`</summary>

```text
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: load balancing (round-robin)
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 0
Down Delay (ms): 0

Slave Interface: eth1
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:92:b2:ab
Slave queue ID: 0

Slave Interface: eth2
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:59:35:12
Slave queue ID: 0
```

</details>

<details><summary>см. содержание `/etc/modprobe.conf`</summary>

```text
alias bond0 bonding
options bond0 mode=0 miimon=100 fail_over_mac=1 
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-bond0`</summary>

```text
DEVICE=bond0
TYPE=Bond
BONDING_MASTER="yes"
IPADDR=10.1.1.1
NETMASK=255.255.255.0
ONBOOT="yes"
USERCTL="no"
BONDING_OPTS="mode=0 miimon=100 fail_over_mac=1"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth1`</summary>

```text
DEVICE=eth1
SLAVE="yes"
MASTER=bond0
BOOTPROTO=none
ONBOOT="yes"
USERCTL="no"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth2`</summary>

```text
DEVICE=eth2
SLAVE="yes"
MASTER=bond0
BOOTPROTO=none
ONBOOT="yes"
USERCTL="no"
```

</details>

<details><summary>см. лог `ip a`</summary>

```text
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86095sec preferred_lft 86095sec
    inet6 fe80::5054:ff:fe4d:77d3/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:92:b2:ab brd ff:ff:ff:ff:ff:ff
4: eth2: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:92:b2:ab brd ff:ff:ff:ff:ff:ff
5: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 08:00:27:92:b2:ab brd ff:ff:ff:ff:ff:ff
    inet 10.1.1.1/24 brd 10.1.1.255 scope global bond0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe92:b2ab/64 scope link 
       valid_lft forever preferred_lft forever
```

</details>

<details><summary>см. лог `ip r`</summary>

```text
default via 10.0.2.2 dev eth0 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 
10.1.1.0/24 dev bond0 proto kernel scope link src 10.1.1.1 
```

</details>

<details><summary>см. лог `ping -s 64 -c 4 10.1.1.2`</summary>

```text
PING 10.1.1.2 (10.1.1.2) 64(92) bytes of data.
72 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=0.371 ms
72 bytes from 10.1.1.2: icmp_seq=2 ttl=64 time=0.931 ms
72 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=0.888 ms
72 bytes from 10.1.1.2: icmp_seq=4 ttl=64 time=0.485 ms

--- 10.1.1.2 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3006ms
rtt min/avg/max/mdev = 0.371/0.668/0.931/0.246 ms
```

</details>

Для `centralRouter`:


<details><summary>см. содержание `/proc/net/bonding/bond0`</summary>

```text
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: load balancing (round-robin)
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 0
Down Delay (ms): 0

Slave Interface: eth1
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 1
Permanent HW addr: 08:00:27:12:1d:65
Slave queue ID: 0

Slave Interface: eth2
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 1
Permanent HW addr: 08:00:27:c3:3c:fe
Slave queue ID: 0
```

</details>

<details><summary>см. содержание `/etc/modprobe.conf`</summary>

```text
alias bond0 bonding
options bond0 mode=0 miimon=100 fail_over_mac=1 
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-bond0`</summary>

```text
DEVICE=bond0
TYPE=Bond
BONDING_MASTER="yes"
IPADDR=10.1.1.2
NETMASK=255.255.255.0
GATEWAY=10.1.1.1
ONBOOT="yes"
USERCTL="no"
BONDING_OPTS="mode=0 miimon=100 fail_over_mac=1"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth1`</summary>

```text
DEVICE=eth1
SLAVE="yes"
MASTER=bond0
BOOTPROTO=none
ONBOOT="yes"
USERCTL="no"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth2`</summary>

```text
DEVICE=eth2
SLAVE="yes"
MASTER=bond0
BOOTPROTO=none
ONBOOT="yes"
USERCTL="no"
```

</details>

<details><summary>см. лог `ip a`</summary>

```text
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86088sec preferred_lft 86088sec
    inet6 fe80::5054:ff:fe4d:77d3/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:12:1d:65 brd ff:ff:ff:ff:ff:ff
4: eth2: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:12:1d:65 brd ff:ff:ff:ff:ff:ff
5: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 08:00:27:12:1d:65 brd ff:ff:ff:ff:ff:ff
    inet 10.1.1.2/24 brd 10.1.1.255 scope global bond0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe12:1d65/64 scope link 
       valid_lft forever preferred_lft forever
```

</details>

<details><summary>см. лог `ip r`</summary>

```text
default via 10.0.2.2 dev eth0 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 
10.1.1.0/24 dev bond0 proto kernel scope link src 10.1.1.2 
```

</details>

<details><summary>см. лог `ping -s 64 -c 4 10.1.1.1`</summary>

```text
PING 10.1.1.1 (10.1.1.1) 64(92) bytes of data.
72 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.425 ms
72 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.877 ms
72 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=0.858 ms
72 bytes from 10.1.1.1: icmp_seq=4 ttl=64 time=0.890 ms

--- 10.1.1.1 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3010ms
rtt min/avg/max/mdev = 0.425/0.762/0.890/0.197 ms
```

</details>

## Вопросы

Изначально в Vagrantfile были 2 независимых канала связи centralRouter и inetRouter: "channel_1" и "channel_2"
```shell
# centralRouter
{adapter: 2, virtualbox__intnet: "channel_1"}, 
{adapter: 3, virtualbox__intnet: "channel_2"}
...
#  inetRouter
{adapter: 2, virtualbox__intnet: "channel_1"}, 
{adapter: 3, virtualbox__intnet: "channel_2"}
```
Почему-то PING был изначально с потерями? Куда копать?


<details><summary>см. лог `ping -s 64 -c 4 10.1.1.1`</summary>

```text
PING 10.1.1.1 (10.1.1.1) 64(92) bytes of data.
72 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.936 ms

--- 10.1.1.1 ping statistics ---
4 packets transmitted, 1 received, 75% packet loss, time 3007ms
rtt min/avg/max/mdev = 0.936/0.936/0.936/0.000 ms
```

</details>

По рекомендации для отладки я поменял в Vagrantfile у всех интерфейсов `virtualbox__intnet` на одинаковое значение (хотя внутренне мне кажестя неправильным, так как так не протестировать "резервирование" и "отказоустойчивость" на приближенном к боевому). Да, пинг стал стабилен.

Но при дальнейшем тестировании при пинге с inetRouter, если на centralRouter `sudo ip link set eth2 down` - пинг продолжает идти.
Если вернуть `sudo ip link set eth2 up` и отключить первый `sudo ip link set eth1 down` - пинг ПРОПАДАЕТ.
Почему?

inetRouter | centralRouter
 --- | --- 
[vagrant@inetRouter ~]$  ping  10.1.1.2 | 
PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data. | 
64 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=0.907 ms | 
64 bytes from 10.1.1.2: icmp_seq=2 ttl=64 time=0.643 ms | 
64 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=1.82 ms | [vagrant@centralRouter ~]$  sudo ip link set eth2 down
64 bytes from 10.1.1.2: icmp_seq=4 ttl=64 time=0.821 ms | # ping идет, как видим
64 bytes from 10.1.1.2: icmp_seq=5 ttl=64 time=0.764 ms | [vagrant@centralRouter ~]$  cat /proc/net/bonding/bond0
64 bytes from 10.1.1.2: icmp_seq=6 ttl=64 time=1.83 ms | ...
64 bytes from 10.1.1.2: icmp_seq=7 ttl=64 time=0.803 ms | Slave Interface: eth2
64 bytes from 10.1.1.2: icmp_seq=8 ttl=64 time=0.675 ms | MII Status: down
64 bytes from 10.1.1.2: icmp_seq=9 ttl=64 time=0.738 ms | ...
64 bytes from 10.1.1.2: icmp_seq=10 ttl=64 time=0.714 ms | Link Failure Count: 1
64 bytes from 10.1.1.2: icmp_seq=11 ttl=64 time=0.869 ms | ...
64 bytes from 10.1.1.2: icmp_seq=12 ttl=64 time=1.56 ms | [vagrant@centralRouter ~]$ sudo ip link set eth2 up
64 bytes from 10.1.1.2: icmp_seq=13 ttl=64 time=0.708 ms | [vagrant@centralRouter ~]$ sudo ip link set eth1 down
. | # ping больше не идет. 
. | # Почему?
. | [vagrant@centralRouter ~]$ sudo ip link set eth1 up
64 bytes from 10.1.1.2: icmp_seq=53 ttl=64 time=0.383 ms | # ping пошел. 
64 bytes from 10.1.1.2: icmp_seq=53 ttl=64 time=0.941 ms | 
