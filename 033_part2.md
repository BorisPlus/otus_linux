#  Сетевые пакеты. LACP 

Начну c того, что для реализации рабочего стенда было перелопачено достаточно много материала. Менялись дистрибутивы, менялись ядра, менялись версии операционок, менялись утилиты настройки (Итог - CentOS 7 и БЕЗ NetworkManager). С целью экономии времени разработки и отладки я развернул отдельный стенд для этой задачи, просто 2 узла и 2 канала между ними. Если действительно необходимо для сдачи ДЗ, то я объединю блок с общим репозиторием сети "предприятия". Но "математика" одна (названия узлов сохранены).

* https://centos.name/?page/tipsandtricks/BondingInterfaces
* https://ahelpme.com/linux/centos-8/adding-bonding-interface-to-centos-8-editing-configuration-files-only/
* https://github.com/simonmcc/vagrant-bond/blob/master/shell/convert2bond.sh
* https://help.ubuntu.com/community/UbuntuBonding
* https://admin-d.livejournal.com/5217.html

## Исполнение

Очень важно понимать, что должно быть именно ДВА независимых ФИЗИЧЕСКИХ канала, будто это два провайдера. Соответственно в [Vagrantfile](./033_part2/vm/Vagrantfile) это каналы адапторов: 

<details><summary>см. Vagrantfile</summary>

```text
# -*- mode: ruby -*-
# vim: set ft=ruby :

MACHINES = {
    :inetRouter => {
        :box_name => "centos/7",
        :net => [
            {adapter: 2, virtualbox__intnet: "channel_1",},
            {adapter: 3, virtualbox__intnet: "channel_2",}
        ]
    },
    :centralRouter => {
        :box_name => "centos/7",
        :net => [
            {adapter: 2, virtualbox__intnet: "channel_1",},
            {adapter: 3, virtualbox__intnet: "channel_2",},
        ]
    },
}

Vagrant.configure("2") do |config|

    MACHINES.each do |boxname, boxconfig|
        config.gatling.rsync_on_startup = false
        config.vm.define boxname do |box|
            box.vm.provision "shell", run: "always", inline: <<-SHELL

                systemctl stop NetworkManager    # <--- No once anymore
                systemctl disable NetworkManager # <--- No once anymore

                systemctl enable network.service
                systemctl start network.service

            SHELL

            config.vm.provider "virtualbox" do |v|
                v.memory = 256
                v.cpus = 1
            end

            box.vm.box = boxconfig[:box_name]
            box.vm.host_name = boxname.to_s

            boxconfig[:net].each do |ipconf|
                box.vm.network "private_network", ipconf
            end

            box.vm.provision "shell", inline: <<-SHELL
                mkdir -p ~root/.ssh
                cp ~vagrant/.ssh/auth* ~root/.ssh
            SHELL

        end
    end
end

```

</details>

```shell
cd ../vm/
vagrant destroy -f && vagrant up 
python3 v2a.py -o ../ansible/inventories/hosts # Это уже как кредо
cd ../ansible/
ansible-playbook playbooks/create_bond.yml > ../files/playbooks_create_bond.yml.log
```

[лог `ansible-playbook playbooks/create_bond.yml`](./033_part2/files/playbooks_create_bond.yml.log)

<details><summary>см. лог `ansible-playbook playbooks/create_bond.yml`</summary>

```text

PLAY [Playbook of bond config] *************************************************

TASK [Gathering Facts] *********************************************************
ok: [centralRouter]
ok: [inetRouter]

TASK [../roles/create_bond : /etc/sysconfig/network | "NOZEROCONF=yes" | I don't want 169.254.0.0/16 network at default] ***
changed: [inetRouter]
changed: [centralRouter]

TASK [../roles/create_bond : /etc/sysconfig/network-scripts/ifcfg-<bonded> | delete interfaces] ***
changed: [inetRouter] => (item={'DEVICE': 'bond0', 'NAME': 'bond0', 'TYPE': 'Bond', 'BONDING_MASTER': 'yes', 'IPADDR': '192.168.1.1', 'NETMASK': '255.255.255.252', 'ONBOOT': 'yes', 'DEFROUTE': 'yes', 'USERCTL': 'no', 'BONDING_OPTS': '"mode=1 miimon=100 primary=eth1 primary=eth2 primary_select=always downdelay=200 updelay=200"'})
changed: [centralRouter] => (item={'DEVICE': 'bond0', 'NAME': 'bond0', 'TYPE': 'Bond', 'BONDING_MASTER': 'yes', 'IPADDR': '192.168.1.2', 'NETMASK': '255.255.255.252', 'GATEWAY': '192.168.1.1', 'ONBOOT': 'yes', 'DEFROUTE': 'yes', 'USERCTL': 'no', 'BONDING_OPTS': '"mode=1 miimon=100 primary=eth1 primary=eth2 primary_select=always downdelay=200 updelay=200"'})
changed: [inetRouter] => (item={'DEVICE': 'eth1', 'NAME': 'eth1', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [centralRouter] => (item={'DEVICE': 'eth1', 'NAME': 'eth1', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [inetRouter] => (item={'DEVICE': 'eth2', 'NAME': 'eth2', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [centralRouter] => (item={'DEVICE': 'eth2', 'NAME': 'eth2', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})

TASK [../roles/create_bond : /etc/sysconfig/network-scripts/ifcfg-<bonded> | create bond] ***
changed: [inetRouter] => (item={'DEVICE': 'bond0', 'NAME': 'bond0', 'TYPE': 'Bond', 'BONDING_MASTER': 'yes', 'IPADDR': '192.168.1.1', 'NETMASK': '255.255.255.252', 'ONBOOT': 'yes', 'DEFROUTE': 'yes', 'USERCTL': 'no', 'BONDING_OPTS': '"mode=1 miimon=100 primary=eth1 primary=eth2 primary_select=always downdelay=200 updelay=200"'})
changed: [centralRouter] => (item={'DEVICE': 'bond0', 'NAME': 'bond0', 'TYPE': 'Bond', 'BONDING_MASTER': 'yes', 'IPADDR': '192.168.1.2', 'NETMASK': '255.255.255.252', 'GATEWAY': '192.168.1.1', 'ONBOOT': 'yes', 'DEFROUTE': 'yes', 'USERCTL': 'no', 'BONDING_OPTS': '"mode=1 miimon=100 primary=eth1 primary=eth2 primary_select=always downdelay=200 updelay=200"'})
changed: [inetRouter] => (item={'DEVICE': 'eth1', 'NAME': 'eth1', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [centralRouter] => (item={'DEVICE': 'eth1', 'NAME': 'eth1', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [inetRouter] => (item={'DEVICE': 'eth2', 'NAME': 'eth2', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})
changed: [centralRouter] => (item={'DEVICE': 'eth2', 'NAME': 'eth2', 'TYPE': 'Ethernet', 'SLAVE': 'yes', 'MASTER': 'bond0', 'BOOTPROTO': 'none', 'ONBOOT': 'yes', 'USERCTL': 'no', 'NM_CONTROLLED': 'no'})

RUNNING HANDLER [../roles/create_bond : systemctl-restart-network] *************
changed: [centralRouter]
changed: [inetRouter]

PLAY RECAP *********************************************************************
centralRouter              : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
inetRouter                 : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


```

</details>

## Демонстрация работоспособности

__Замечание__: `/etc/modprobe.conf` - не используется в новых версиях (deprecated)
__Замечание__: `/etc/modprobe.d/bonding.conf` - возможно не использовать
__Замечание__: `ls /sys/class/net/bond0/bonding/` - все опции

```shell
ansible-playbook playbooks/demonstrate.yml 
```

Для `inetRouter`:

<details><summary>см. содержание `/proc/net/bonding/bond0`</summary>

```text
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: fault-tolerance (active-backup)
Primary Slave: eth1 (primary_reselect always)
Currently Active Slave: eth1
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 200
Down Delay (ms): 200

Slave Interface: eth1
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:b0:a8:35
Slave queue ID: 0

Slave Interface: eth2
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:27:4e:e7
Slave queue ID: 0
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-bond0`</summary>

```text
DEVICE=bond0
NAME=bond0
TYPE=Bond
BONDING_MASTER=yes
IPADDR=192.168.1.1
NETMASK=255.255.255.252
ONBOOT=yes
DEFROUTE=yes
USERCTL=no
BONDING_OPTS="mode=1 miimon=100 primary=eth1 primary_select=always downdelay=200 updelay=200"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth1`</summary>

```text
DEVICE=eth1
NAME=eth1
TYPE=Ethernet
SLAVE=yes
MASTER=bond0
BOOTPROTO=none
ONBOOT=yes
USERCTL=no
NM_CONTROLLED=no
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth2`</summary>

```text
DEVICE=eth2
NAME=eth2
TYPE=Ethernet
SLAVE=yes
MASTER=bond0
BOOTPROTO=none
ONBOOT=yes
USERCTL=no
NM_CONTROLLED=no
```

</details>

<details><summary>см. лог `ip a`</summary>

```text
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86333sec preferred_lft 86333sec
    inet6 fe80::5054:ff:fe4d:77d3/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:b0:a8:35 brd ff:ff:ff:ff:ff:ff
4: eth2: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:b0:a8:35 brd ff:ff:ff:ff:ff:ff
5: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 08:00:27:b0:a8:35 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.1/30 brd 192.168.1.3 scope global bond0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:feb0:a835/64 scope link 
       valid_lft forever preferred_lft forever
```

</details>

<details><summary>см. лог `ip r`</summary>

```text
default via 10.0.2.2 dev eth0 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 
192.168.1.0/30 dev bond0 proto kernel scope link src 192.168.1.1 
```

</details>

<details><summary>см. лог `ping -s 64 -c 4 192.168.1.2`</summary>

```text
PING 192.168.1.2 (192.168.1.2) 56(84) bytes of data.

--- 192.168.1.2 ping statistics ---
4 packets transmitted, 0 received, 100% packet loss, time 2999ms
```

</details>

Для `centralRouter`:

<details><summary>см. содержание `/proc/net/bonding/bond0`</summary>

```text
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: fault-tolerance (active-backup)
Primary Slave: eth1 (primary_reselect always)
Currently Active Slave: eth1
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 200
Down Delay (ms): 200

Slave Interface: eth1
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:b0:ce:4a
Slave queue ID: 0

Slave Interface: eth2
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 08:00:27:84:e8:54
Slave queue ID: 0
```

</details>

```text

```


<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-bond0`</summary>

```text
DEVICE=bond0
NAME=bond0
TYPE=Bond
BONDING_MASTER=yes
IPADDR=192.168.1.2
NETMASK=255.255.255.252
GATEWAY=192.168.1.1
ONBOOT=yes
DEFROUTE=yes
USERCTL=no
BONDING_OPTS="mode=1 miimon=100 primary=eth1 primary_select=always downdelay=200 updelay=200"
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth1`</summary>

```text
DEVICE=eth1
NAME=eth1
TYPE=Ethernet
SLAVE=yes
MASTER=bond0
BOOTPROTO=none
ONBOOT=yes
USERCTL=no
NM_CONTROLLED=no
```

</details>

<details><summary>см. содержание `/etc/sysconfig/network-scripts/ifcfg-eth2`</summary>

```text
DEVICE=eth2
NAME=eth2
TYPE=Ethernet
SLAVE=yes
MASTER=bond0
BOOTPROTO=none
ONBOOT=yes
USERCTL=no
NM_CONTROLLED=no
```

</details>

<details><summary>см. лог `ip a`</summary>

```text
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86333sec preferred_lft 86333sec
    inet6 fe80::5054:ff:fe4d:77d3/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:b0:ce:4a brd ff:ff:ff:ff:ff:ff
4: eth2: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master bond0 state UP group default qlen 1000
    link/ether 08:00:27:b0:ce:4a brd ff:ff:ff:ff:ff:ff
5: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 08:00:27:b0:ce:4a brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.2/30 brd 192.168.1.3 scope global bond0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:feb0:ce4a/64 scope link 
       valid_lft forever preferred_lft forever
```

</details>

<details><summary>см. лог `ip r`</summary>

```text
default via 10.0.2.2 dev eth0 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 
192.168.1.0/30 dev bond0 proto kernel scope link src 192.168.1.2 
```

</details>

<details><summary>см. лог `ping -s 64 -c 4 192.168.1.1`</summary>

```text
PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.
From 192.168.1.2 icmp_seq=1 Destination Host Unreachable
From 192.168.1.2 icmp_seq=2 Destination Host Unreachable
From 192.168.1.2 icmp_seq=3 Destination Host Unreachable
From 192.168.1.2 icmp_seq=4 Destination Host Unreachable

--- 192.168.1.1 ping statistics ---
4 packets transmitted, 0 received, +4 errors, 100% packet loss, time 2999ms
pipe 4
```

</details>

## Вопросы

Изначально в Vagrantfile были 2 независимых канала связи centralRouter и inetRouter: "channel_1" и "channel_2"
```shell
# centralRouter
{adapter: 2, virtualbox__intnet: "channel_1"}, 
{adapter: 3, virtualbox__intnet: "channel_2"}
...
#  inetRouter
{adapter: 2, virtualbox__intnet: "channel_1"}, 
{adapter: 3, virtualbox__intnet: "channel_2"}
```

Пинг не шел абсолютно.


<details><summary>см. лог `ping`</summary>

```text
[vagrant@inetRouter ~]$ ping -c 4 192.168.1.2
PING 192.168.1.2 (192.168.1.2) 56(84) bytes of data.
From 192.168.1.1 icmp_seq=1 Destination Host Unreachable
From 192.168.1.1 icmp_seq=2 Destination Host Unreachable
From 192.168.1.1 icmp_seq=3 Destination Host Unreachable
From 192.168.1.1 icmp_seq=4 Destination Host Unreachable

--- 192.168.1.2 ping statistics ---
4 packets transmitted, 0 received, +4 errors, 100% packet loss, time 3000ms
pipe 4


[vagrant@centralRouter ~]$ ping -c 4 192.168.1.1
PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.

--- 192.168.1.1 ping statistics ---
4 packets transmitted, 0 received, 100% packet loss, time 3000ms


```

</details>

По рекомендации для отладки я поменял в Vagrantfile у всех интерфейсов `virtualbox__intnet` на одинаковое значение (хотя это не дает приблизится к боевому "резервированию" и "отказоустойчивости"). Ситуация сдвинулась с места, но не до конца.

При дальнейшем тестировании при пинге с inetRouter, если на centralRouter `sudo ip link set eth2 down` - пинг продолжает идти.
Если вернуть `sudo ip link set eth2 up` и отключить первый `sudo ip link set eth1 down` - пинг ПРОПАДАЕТ.
Почему?

inetRouter (192.168.1.1) | centralRouter (192.168.1.2)
 --- | --- 
[vagrant@inetRouter ~]$  ping  192.168.1.2 | 
PING 192.168.1.2 (192.168.1.2) 56(84) bytes of data. | 
64 bytes from 192.168.1.2: icmp_seq=1 ttl=64 time=0.907 ms | 
64 bytes from 192.168.1.2: icmp_seq=2 ttl=64 time=0.643 ms | 
64 bytes from 192.168.1.2: icmp_seq=3 ttl=64 time=1.82 ms | [vagrant@centralRouter ~]$  sudo ip link set eth2 down
64 bytes from 192.168.1.2: icmp_seq=4 ttl=64 time=0.821 ms | # ping идет, как видим
64 bytes from 192.168.1.2: icmp_seq=5 ttl=64 time=0.764 ms | [vagrant@centralRouter ~]$  cat /proc/net/bonding/bond0
64 bytes from 192.168.1.2: icmp_seq=6 ttl=64 time=1.83 ms | ...
64 bytes from 192.168.1.2: icmp_seq=7 ttl=64 time=0.803 ms | Slave Interface: eth2
64 bytes from 192.168.1.2: icmp_seq=8 ttl=64 time=0.675 ms | MII Status: down
64 bytes from 192.168.1.2: icmp_seq=9 ttl=64 time=0.738 ms | ...
64 bytes from 192.168.1.2: icmp_seq=10 ttl=64 time=0.714 ms | Link Failure Count: 1
64 bytes from 192.168.1.2: icmp_seq=11 ttl=64 time=0.869 ms | ...
64 bytes from 192.168.1.2: icmp_seq=12 ttl=64 time=1.56 ms | [vagrant@centralRouter ~]$ sudo ip link set eth2 up
64 bytes from 192.168.1.2: icmp_seq=13 ttl=64 time=0.708 ms | [vagrant@centralRouter ~]$ sudo ip link set eth1 down
. | # ping больше не идет. 
From 192.168.1.1 icmp_seq=14 Destination Host Unreachable | # Почему?
From 192.168.1.1 icmp_seq=15 Destination Host Unreachable | [vagrant@centralRouter ~]$  cat /proc/net/bonding/bond0
From 192.168.1.1 icmp_seq=16 Destination Host Unreachable | ...
. | Bonding Mode: fault-tolerance (active-backup)
. | Primary Slave: eth1 (primary_reselect always)    <----- как Slave
. | Currently Active Slave: eth2 <--- он переключился таки ---------.
. | ...                                                             |
. | Slave Interface: eth1                                           |
. | MII Status: down --->--->--->--->-------------------------------'
. | ...
. | #  но ping больше не идет.
From 192.168.1.1 icmp_seq=17 Destination Host Unreachable | [vagrant@centralRouter ~]$ sudo ip link set eth1 up
64 bytes from 192.168.1.2: icmp_seq=18 ttl=64 time=0.383 ms | # ping пошел. 
64 bytes from 192.168.1.2: icmp_seq=19 ttl=64 time=0.941 ms | 


Я умываю руки...